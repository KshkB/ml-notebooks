{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17d5f53e-b980-46e3-bf8b-b64178381074",
   "metadata": {},
   "source": [
    "# TITANIC - KAGGLE\n",
    "\n",
    "### ML ANALYSIS WITH SCI-KIT LEARN\n",
    "\n",
    "We look at machine learning models based on the following classifiers, initiated with their default hyperparameter values:\n",
    "\n",
    "- perceptron;\n",
    "- logistic regression;\n",
    "- support vector machine;\n",
    "- naive Bayes;\n",
    "- decision tree;\n",
    "- random forest;\n",
    "- $k$-nearest neighbours.\n",
    "\n",
    "#### LIBRARY IMPORTS (PREPROCESSING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "760978c4-ad5e-4ba0-b09d-e31578d42d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ml_generals as ml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf03cdfe-fca3-4bc0-8feb-b524c707009d",
   "metadata": {},
   "source": [
    "### DATASET IMPORTS\n",
    "\n",
    "In the folder `datasets/` we have prepared the training data, labels and test data saved as:\n",
    "\n",
    "- `trainingData.csv`;\n",
    "- `trainingLabels.csv`;\n",
    "- `testData.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecb19be1-d2f2-4185-a912-298d134d5c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('datasets/trainingData.csv')\n",
    "labels = pd.read_csv('datasets/trainingLabels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3277702-7b8a-46d2-9c70-a8c14465201f",
   "metadata": {},
   "source": [
    "The machine learning models typically pass `numpy` arrays. The above datasets are accordingly transformed:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "250bc6c7-3228-4cce-bca7-9e232d0aa04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.to_numpy()\n",
    "labels = labels.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea024e0-8d61-476b-b700-82b4b1bb485d",
   "metadata": {},
   "source": [
    "### PREPROCESSING\n",
    "\n",
    "Before preparing the datasets for model training, we can normalize values to generate more accurate predictions with the `StandardScalar()` method.\n",
    "\n",
    "**Note.** *We do not normalise the labels. Only the features (training data).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "609d0f19-f3c3-4f9e-ae55-009b9147dbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainNormalised = StandardScaler().fit_transform(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878f888f-0668-4ce3-9ea1-a6b45703e1d6",
   "metadata": {},
   "source": [
    "The method `train_test_split` allows for validation testing by machine learning models while training. It takes the training data with its labels and splits it into data for training and testing (validating).\n",
    "\n",
    "The `test_size` parameter determines what percentage the training data to reserve for validation testing. Splits `30:70` are commonly used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "346db9db-4608-44cd-88f7-93d8cd0cf6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_size = 0.3 # modify as you wish\n",
    "\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(\n",
    "    trainNormalised,\n",
    "    labels,\n",
    "    test_size=tst_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77b944c-1158-4582-a3c3-404cbd6010ed",
   "metadata": {},
   "source": [
    "### MODEL TRAINING \n",
    "\n",
    "#### CLASSIFIER IMPORTS\n",
    "\n",
    "We import the following classifiers from the `sklearn` library:\n",
    "\n",
    "- perceptron;\n",
    "- logistic regression;\n",
    "- support vector machine;\n",
    "- naive Bayes;\n",
    "- decision tree;\n",
    "- random forest;\n",
    "- $k$-nearest neighbour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fedb61b7-22bc-4711-bcc8-77dea28f58c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea7d6a7-4244-411e-bf09-db449f498d28",
   "metadata": {},
   "source": [
    "#### INITIALISING THE MODELS\n",
    "\n",
    "Above we have imported a number of machine learning classifiers. These are initialized below with their default hyperparameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce03c10c-7698-4388-96e4-1852091cce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_pcp = Perceptron()\n",
    "classifier_lr = LogisticRegression()\n",
    "classifier_SVC = SVC()\n",
    "classifier_gnb = GaussianNB()\n",
    "classifier_dt = DecisionTreeClassifier()\n",
    "classifier_rf = RandomForestClassifier()\n",
    "classifier_knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986af2e6-621c-487e-bffd-68d00c68e218",
   "metadata": {},
   "source": [
    "#### FITTING THE MODELS\n",
    "\n",
    "The above models are fit by calling the `.fit()` method and passing `data_train` and `labels_train` from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38ea828a-ce3e-4a75-a7a2-7dd05cd25d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_pcp.fit(data_train, labels_train)\n",
    "classifier_lr.fit(data_train, labels_train)\n",
    "classifier_SVC.fit(data_train, labels_train)\n",
    "classifier_gnb.fit(data_train, labels_train)\n",
    "classifier_dt.fit(data_train, labels_train)\n",
    "classifier_rf.fit(data_train, labels_train)\n",
    "classifier_knn.fit(data_train, labels_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de66444-af2e-4173-86a6-dd0815d0dc38",
   "metadata": {},
   "source": [
    "### MODEL RESULTS\n",
    "\n",
    "The method `modelValidationResults` in the module `ml_generals.py` passes in the models above, evaluates them on the testing set `data_test, labels_test` and returns a tuple object. The tuples are:\n",
    "\n",
    "- Accuracy score;\n",
    "- ROC-AUC Score;\n",
    "- Confusion matrix;\n",
    "- Cross validation score;\n",
    "- Aggregate score.\n",
    "\n",
    "We can build a pandas dataframe now with these columns, along with the classifier name and aggregate score, for each model above as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "573efdca-db9a-4da7-bc40-41125e28ac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    Perceptron.__name__,\n",
    "    LogisticRegression.__name__,\n",
    "    SVC.__name__,\n",
    "    GaussianNB.__name__,\n",
    "    DecisionTreeClassifier.__name__,\n",
    "    RandomForestClassifier.__name__,\n",
    "    KNeighborsClassifier.__name__\n",
    "]\n",
    "\n",
    "fitted_models = [\n",
    "    classifier_pcp, \n",
    "    classifier_lr,\n",
    "    classifier_SVC,\n",
    "    classifier_gnb,\n",
    "    classifier_dt,\n",
    "    classifier_rf,\n",
    "    classifier_knn\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401f568d-9983-4d1d-9416-a467fef17202",
   "metadata": {},
   "source": [
    "#### THE RESULTS DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "509481ad-5fd0-4414-813f-afc86041e45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_columns = [\n",
    "    'Classifier',\n",
    "    'Accuracy score',\n",
    "    'ROC-AUC score',\n",
    "    'Confusion Matrix',\n",
    "    'Cross validation score', \n",
    "    'Aggregate score'\n",
    "]\n",
    "results_df = pd.DataFrame(columns = results_columns)\n",
    "\n",
    "for i, clss in enumerate(fitted_models):\n",
    "    name = [model_names[i]]\n",
    "    rsults = ml.modelValidationResults(\n",
    "        clss, \n",
    "        train=data_train, \n",
    "        train_labels=labels_train, \n",
    "        test=data_test,\n",
    "        test_labels=labels_test\n",
    "    )\n",
    "    accScore = rsults[0]\n",
    "    rocaucScore = rsults[1]\n",
    "    crssval = rsults[-1]\n",
    "\n",
    "    lst = [name] + [rsults] \n",
    "    lst_flattened = [item for sublst in lst for item in sublst]\n",
    "    results_df = results_df.append(pd.Series(lst_flattened, index = results_columns), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1eb28c66-e914-4a95-8645-10178c806fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_a88f8_\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Classifier</th>        <th class=\"col_heading level0 col1\" >Accuracy score</th>        <th class=\"col_heading level0 col2\" >ROC-AUC score</th>        <th class=\"col_heading level0 col3\" >Confusion Matrix</th>        <th class=\"col_heading level0 col4\" >Cross validation score</th>        <th class=\"col_heading level0 col5\" >Aggregate score</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_a88f8_row0_col0\" class=\"data row0 col0\" >Perceptron</td>\n",
       "                        <td id=\"T_a88f8_row0_col1\" class=\"data row0 col1\" >0.735075</td>\n",
       "                        <td id=\"T_a88f8_row0_col2\" class=\"data row0 col2\" >0.732024</td>\n",
       "                        <td id=\"T_a88f8_row0_col3\" class=\"data row0 col3\" >[[125  43]\n",
       " [ 28  72]]</td>\n",
       "                        <td id=\"T_a88f8_row0_col4\" class=\"data row0 col4\" >0.737020</td>\n",
       "                        <td id=\"T_a88f8_row0_col5\" class=\"data row0 col5\" >0.734706</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a88f8_row1_col0\" class=\"data row1 col0\" >LogisticRegression</td>\n",
       "                        <td id=\"T_a88f8_row1_col1\" class=\"data row1 col1\" >0.817164</td>\n",
       "                        <td id=\"T_a88f8_row1_col2\" class=\"data row1 col2\" >0.801548</td>\n",
       "                        <td id=\"T_a88f8_row1_col3\" class=\"data row1 col3\" >[[145  23]\n",
       " [ 26  74]]</td>\n",
       "                        <td id=\"T_a88f8_row1_col4\" class=\"data row1 col4\" >0.780210</td>\n",
       "                        <td id=\"T_a88f8_row1_col5\" class=\"data row1 col5\" >0.799641</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a88f8_row2_col0\" class=\"data row2 col0\" >SVC</td>\n",
       "                        <td id=\"T_a88f8_row2_col1\" class=\"data row2 col1\" >0.824627</td>\n",
       "                        <td id=\"T_a88f8_row2_col2\" class=\"data row2 col2\" >0.777143</td>\n",
       "                        <td id=\"T_a88f8_row2_col3\" class=\"data row2 col3\" >[[162   6]\n",
       " [ 41  59]]</td>\n",
       "                        <td id=\"T_a88f8_row2_col4\" class=\"data row2 col4\" >0.791423</td>\n",
       "                        <td id=\"T_a88f8_row2_col5\" class=\"data row2 col5\" >0.797731</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a88f8_row3_col0\" class=\"data row3 col0\" >GaussianNB</td>\n",
       "                        <td id=\"T_a88f8_row3_col1\" class=\"data row3 col1\" >0.805970</td>\n",
       "                        <td id=\"T_a88f8_row3_col2\" class=\"data row3 col2\" >0.794643</td>\n",
       "                        <td id=\"T_a88f8_row3_col3\" class=\"data row3 col3\" >[[141  27]\n",
       " [ 25  75]]</td>\n",
       "                        <td id=\"T_a88f8_row3_col4\" class=\"data row3 col4\" >0.778571</td>\n",
       "                        <td id=\"T_a88f8_row3_col5\" class=\"data row3 col5\" >0.793061</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a88f8_row4_col0\" class=\"data row4 col0\" >DecisionTreeClassifier</td>\n",
       "                        <td id=\"T_a88f8_row4_col1\" class=\"data row4 col1\" >0.798507</td>\n",
       "                        <td id=\"T_a88f8_row4_col2\" class=\"data row4 col2\" >0.778571</td>\n",
       "                        <td id=\"T_a88f8_row4_col3\" class=\"data row4 col3\" >[[144  24]\n",
       " [ 30  70]]</td>\n",
       "                        <td id=\"T_a88f8_row4_col4\" class=\"data row4 col4\" >0.788351</td>\n",
       "                        <td id=\"T_a88f8_row4_col5\" class=\"data row4 col5\" >0.788477</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a88f8_row5_col0\" class=\"data row5 col0\" >RandomForestClassifier</td>\n",
       "                        <td id=\"T_a88f8_row5_col1\" class=\"data row5 col1\" >0.824627</td>\n",
       "                        <td id=\"T_a88f8_row5_col2\" class=\"data row5 col2\" >0.805476</td>\n",
       "                        <td id=\"T_a88f8_row5_col3\" class=\"data row5 col3\" >[[148  20]\n",
       " [ 27  73]]</td>\n",
       "                        <td id=\"T_a88f8_row5_col4\" class=\"data row5 col4\" >0.778751</td>\n",
       "                        <td id=\"T_a88f8_row5_col5\" class=\"data row5 col5\" >0.802951</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a88f8_row6_col0\" class=\"data row6 col0\" >KNeighborsClassifier</td>\n",
       "                        <td id=\"T_a88f8_row6_col1\" class=\"data row6 col1\" >0.791045</td>\n",
       "                        <td id=\"T_a88f8_row6_col2\" class=\"data row6 col2\" >0.766548</td>\n",
       "                        <td id=\"T_a88f8_row6_col3\" class=\"data row6 col3\" >[[145  23]\n",
       " [ 33  67]]</td>\n",
       "                        <td id=\"T_a88f8_row6_col4\" class=\"data row6 col4\" >0.769099</td>\n",
       "                        <td id=\"T_a88f8_row6_col5\" class=\"data row6 col5\" >0.775564</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x13a57bdc0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124d8698-fa04-44f3-8968-1b9942cdec76",
   "metadata": {},
   "source": [
    "### MODEL PERFORMANCE TRANSCRIPT\n",
    "\n",
    "There are three metrics (columns) by which we can sort model performance. These are:\n",
    "\n",
    "- Accuracy score;\n",
    "- ROC-AUC score;\n",
    "- Cross validation\n",
    "\n",
    "We could also further inspect the entries of the confusion matrix and sort by values in there, e.g., order by true-positive to false-negative ratio, etc. \n",
    "\n",
    "#### BEST ACCURACY SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b2ffce0-b841-4e82-abb2-675b47746186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_0953f_\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Classifier</th>        <th class=\"col_heading level0 col1\" >Accuracy score</th>        <th class=\"col_heading level0 col2\" >ROC-AUC score</th>        <th class=\"col_heading level0 col3\" >Confusion Matrix</th>        <th class=\"col_heading level0 col4\" >Cross validation score</th>        <th class=\"col_heading level0 col5\" >Aggregate score</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_0953f_row0_col0\" class=\"data row0 col0\" >RandomForestClassifier</td>\n",
       "                        <td id=\"T_0953f_row0_col1\" class=\"data row0 col1\" >0.824627</td>\n",
       "                        <td id=\"T_0953f_row0_col2\" class=\"data row0 col2\" >0.805476</td>\n",
       "                        <td id=\"T_0953f_row0_col3\" class=\"data row0 col3\" >[[148  20]\n",
       " [ 27  73]]</td>\n",
       "                        <td id=\"T_0953f_row0_col4\" class=\"data row0 col4\" >0.778751</td>\n",
       "                        <td id=\"T_0953f_row0_col5\" class=\"data row0 col5\" >0.802951</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14905bf70>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values('Accuracy score').iloc[[-1]].style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8abdafb-d5d1-43fc-914a-f202f808adfe",
   "metadata": {},
   "source": [
    "#### BEST ROC-AUC SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d78e52c6-89e1-41eb-8598-0acb1787cd59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_c514d_\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Classifier</th>        <th class=\"col_heading level0 col1\" >Accuracy score</th>        <th class=\"col_heading level0 col2\" >ROC-AUC score</th>        <th class=\"col_heading level0 col3\" >Confusion Matrix</th>        <th class=\"col_heading level0 col4\" >Cross validation score</th>        <th class=\"col_heading level0 col5\" >Aggregate score</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_c514d_row0_col0\" class=\"data row0 col0\" >RandomForestClassifier</td>\n",
       "                        <td id=\"T_c514d_row0_col1\" class=\"data row0 col1\" >0.824627</td>\n",
       "                        <td id=\"T_c514d_row0_col2\" class=\"data row0 col2\" >0.805476</td>\n",
       "                        <td id=\"T_c514d_row0_col3\" class=\"data row0 col3\" >[[148  20]\n",
       " [ 27  73]]</td>\n",
       "                        <td id=\"T_c514d_row0_col4\" class=\"data row0 col4\" >0.778751</td>\n",
       "                        <td id=\"T_c514d_row0_col5\" class=\"data row0 col5\" >0.802951</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14905b0a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values('ROC-AUC score').iloc[[-1]].style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bccba8-0161-426b-b581-94b97912e631",
   "metadata": {},
   "source": [
    "#### BEST CROSS VALIDATION SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "233b5fce-ca04-4f25-9b5d-e0e8d636d500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_82d25_\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Classifier</th>        <th class=\"col_heading level0 col1\" >Accuracy score</th>        <th class=\"col_heading level0 col2\" >ROC-AUC score</th>        <th class=\"col_heading level0 col3\" >Confusion Matrix</th>        <th class=\"col_heading level0 col4\" >Cross validation score</th>        <th class=\"col_heading level0 col5\" >Aggregate score</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_82d25_row0_col0\" class=\"data row0 col0\" >SVC</td>\n",
       "                        <td id=\"T_82d25_row0_col1\" class=\"data row0 col1\" >0.824627</td>\n",
       "                        <td id=\"T_82d25_row0_col2\" class=\"data row0 col2\" >0.777143</td>\n",
       "                        <td id=\"T_82d25_row0_col3\" class=\"data row0 col3\" >[[162   6]\n",
       " [ 41  59]]</td>\n",
       "                        <td id=\"T_82d25_row0_col4\" class=\"data row0 col4\" >0.791423</td>\n",
       "                        <td id=\"T_82d25_row0_col5\" class=\"data row0 col5\" >0.797731</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14905ba60>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values('Cross validation score').iloc[[-1]].style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d891ebc-b623-45ee-aaa1-91ee2211701a",
   "metadata": {},
   "source": [
    "#### BEST AGGREGATE SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27f569ee-e356-40c1-9540-a41130ee1be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_66b45_\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Classifier</th>        <th class=\"col_heading level0 col1\" >Accuracy score</th>        <th class=\"col_heading level0 col2\" >ROC-AUC score</th>        <th class=\"col_heading level0 col3\" >Confusion Matrix</th>        <th class=\"col_heading level0 col4\" >Cross validation score</th>        <th class=\"col_heading level0 col5\" >Aggregate score</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_66b45_row0_col0\" class=\"data row0 col0\" >RandomForestClassifier</td>\n",
       "                        <td id=\"T_66b45_row0_col1\" class=\"data row0 col1\" >0.824627</td>\n",
       "                        <td id=\"T_66b45_row0_col2\" class=\"data row0 col2\" >0.805476</td>\n",
       "                        <td id=\"T_66b45_row0_col3\" class=\"data row0 col3\" >[[148  20]\n",
       " [ 27  73]]</td>\n",
       "                        <td id=\"T_66b45_row0_col4\" class=\"data row0 col4\" >0.778751</td>\n",
       "                        <td id=\"T_66b45_row0_col5\" class=\"data row0 col5\" >0.802951</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x13a2616a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values('Aggregate score').iloc[[-1]].style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b92978-0a07-47d7-8e02-adc67aeb756a",
   "metadata": {},
   "source": [
    "### RETURN BEST FUNCTION\n",
    "\n",
    "The following function passes a metric and returns the classifier which outperformed others with respect to that metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bef15b3-9d10-4863-a758-69f457ce70f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnBest(metric):\n",
    "    \n",
    "    row = results_df.sort_values(metric).iloc[[-1]]\n",
    "    modelName = row['Classifier'].values[0]\n",
    "    modelNameIndex = model_names.index(modelName)\n",
    "    classifier = fitted_models[modelNameIndex]\n",
    "    \n",
    "    return classifier, modelName\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0566abe7-08f7-42dd-9746-7358d3859e2d",
   "metadata": {},
   "source": [
    "### PREDICTIONS\n",
    "\n",
    "The test data prepared earlier is read below. \n",
    "\n",
    "**Note.** *The test data must be normalised in order to be analysed in consistency with the training data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b71ed390-0427-46b9-b2f1-bf1274087b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('datasets/testData.csv')\n",
    "\n",
    "testToPass = test.drop(['PassengerId'], axis=1)\n",
    "testToPass = testToPass.to_numpy()\n",
    "testToPassNormalised = StandardScaler().fit_transform(testToPass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71290dc0-6ba9-4f4f-970f-20575aad2d9c",
   "metadata": {},
   "source": [
    "#### PREDICTIONS DATAFRAME\n",
    "\n",
    "As with the `returnBest` function, the `prediction` function coded below passes in a metric, generates predictions and writes these to a `.csv` file, which is saves in `datasets/` as `predictions.csv`.\n",
    "\n",
    "Code for implementing this is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bc475ff-8171-46f6-bf32-a28549d87f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(metric):\n",
    "    \n",
    "    classifier_best, classifier_name = returnBest(metric)\n",
    "    preds_best = classifier_best.predict(testToPassNormalised)\n",
    "    \n",
    "    predCols = [\n",
    "    'PassengerId',\n",
    "    'Survived'\n",
    "    ]\n",
    "    pred_df = pd.DataFrame(columns = predCols)\n",
    "    \n",
    "    for i, row in test.iterrows():\n",
    "        psngerId = int(row['PassengerId'])\n",
    "        survived = int(preds_best[i])\n",
    "        pred_df = pred_df.append(pd.Series(\n",
    "            [\n",
    "                psngerId,\n",
    "                survived\n",
    "            ], index = predCols\n",
    "        ), ignore_index=True)\n",
    "\n",
    "    pred_df.to_csv('datasets/predictions.csv', index=False)\n",
    "    \n",
    "    print(f\"{classifier_name} performed best with respect to {metric}.\\nPredictions were generated by {classifier_name}.\")\n",
    "    return \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b906a7-b228-4601-9ae7-4fd46f2a9d05",
   "metadata": {},
   "source": [
    "### PREDICTIONS\n",
    "\n",
    "With respect to the metric `Aggregate score`, we have predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46efaaa4-4e2a-4f1d-a9fa-fe7f539adbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier performed best with respect to Aggregate score.\n",
      "Predictions were generated by RandomForestClassifier.\n"
     ]
    }
   ],
   "source": [
    "prediction('Aggregate score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6921b425-ee07-4b71-aee0-56a3f5bc6d6f",
   "metadata": {},
   "source": [
    "### SUBMISSION\n",
    "\n",
    "Uncomment and run to submit predictions via KAGGLE API from the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1330b6c3-093a-48af-98e7-748de918e4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! kaggle competitions submit -c \"titanic\" -f datasets/predictions.csv -m \"submitted from command line\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974662a5-69b0-4ce4-948b-eff29f045ecb",
   "metadata": {},
   "source": [
    "The latest submission scored **0.77033** on KAGGLE. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
