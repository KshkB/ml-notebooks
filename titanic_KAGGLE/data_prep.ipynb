{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b61ea4e-0bcf-4c97-9a0a-38deb5042016",
   "metadata": {},
   "source": [
    "# TITANIC - KAGGLE\n",
    "\n",
    "## DATA PREPARATION\n",
    "\n",
    "#### LIBRARY IMPORTS \n",
    "\n",
    "We will the `pandas` library to inspect data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a2c72e5-7e92-4f8c-aaf0-5efe73327c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa7f855-b02e-4904-9149-d2b4c62c248f",
   "metadata": {},
   "source": [
    "If data isn't already downloaded, uncomment the following and download via the KAGGLE API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b05926eb-f34d-4ff0-9afa-47da7be39875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle competitions download -c \"titanic\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad97eb0-208b-4a9c-93dd-84906503ed5a",
   "metadata": {},
   "source": [
    "Move the `titanic.zip` file to the folder `datasets/`. Unzip that file and move unzipped files to `datasets/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e28d3c38-1f1c-457f-b57f-af906dd3827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! mv titanic.zip datasets/\n",
    "# ! unzip datasets/titanic.zip\n",
    "# ! mv gender_submission.csv datasets/\n",
    "# ! mv test.csv datasets/\n",
    "# ! mv train.csv datasets/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e577d2a9-5659-4437-bf47-2d7e169076ea",
   "metadata": {},
   "source": [
    "Read the training and test data files into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be002753-707b-4d35-877a-74ae0776a890",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = pd.read_csv('datasets/train.csv')\n",
    "testData = pd.read_csv('datasets/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7186fec-fffa-4bcc-bd13-84ac8420f7c5",
   "metadata": {},
   "source": [
    "### PRELIMINARY DATA ANALYSIS\n",
    "\n",
    "Before constructing and implemeting a model, it is necessary to inspect the data sources to sift for relevant and sift out irrelevant data. Note, both the training and test data must have the same data *fields* when implementing a model. We can however remove specific entries from the training data without altering the test data. If we remove an entire column from the training data however, this same column must be removed from the test data.\n",
    "\n",
    "#### TRAINING DATA\n",
    "\n",
    "The following reveals the data fields with `null` or `NaN` entries in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0a2c3eb-348f-470b-9e04-07407a1524d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "177\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "687\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for col in trainData.columns:\n",
    "    print(len(trainData[trainData[col].isnull()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6400201d-97c8-4ecf-a6a2-fae034574723",
   "metadata": {},
   "source": [
    "And more specifically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48833937-e6c4-4c65-9dfc-844b22a8de46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age column has 177 many null or NaN values. This represents 19.87 percent of the training data.\n",
      "Cabin column has 687 many null or NaN values. This represents 77.1 percent of the training data.\n",
      "Embarked column has 2 many null or NaN values. This represents 0.22 percent of the training data.\n"
     ]
    }
   ],
   "source": [
    "trainlength = len(trainData)\n",
    "for col in trainData.columns:\n",
    "    L = len(trainData[trainData[col].isnull()])\n",
    "    if L > 0:\n",
    "        percent = round(100*L/trainlength, 2)\n",
    "        print(f\"{col} column has {L} many null or NaN values. This represents {percent} percent of the training data.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e40c17-ce37-492f-a77c-1881d034b2fd",
   "metadata": {},
   "source": [
    "#### TEST DATA\n",
    "\n",
    "Similarly for test data we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9afaacdb-e748-4c69-b493-b640d548dc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age column has 86 many null or NaN values. This represents 20.57 percent of the testing data.\n",
      "Fare column has 1 many null or NaN values. This represents 0.24 percent of the testing data.\n",
      "Cabin column has 327 many null or NaN values. This represents 78.23 percent of the testing data.\n"
     ]
    }
   ],
   "source": [
    "testLength = len(testData)\n",
    "for col in testData.columns:\n",
    "    L = len(testData[testData[col].isnull()])\n",
    "    if L > 0:\n",
    "        percent = round(100*L/testLength, 2)\n",
    "        print(f\"{col} column has {L} many null or NaN values. This represents {percent} percent of the testing data.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a96dacd-3dfe-40e2-a5a1-482f0577133e",
   "metadata": {},
   "source": [
    "### PRELIMINARY CONCLUSIONS \n",
    "\n",
    "There is missing data in both training and test datasets. To handle this we can look to either:\n",
    "\n",
    "- fill in the data; \n",
    "- exclude it;\n",
    "- train different models and apply them to the cases where data is missing or is not.\n",
    "\n",
    "We look at each field with missing data seperately.\n",
    "\n",
    "#### AGE\n",
    "\n",
    "The `Age` datafield has around `20%` of unfilled values over both the training and test data. This is typically not enough to warrent excluding `Age` entirely. A better option might be to used a mixed model approach: to train a model including `Age` and one excluding `Age`. Then apply one of the two models on the testing data if `Age` is known or not.  \n",
    "\n",
    "In this notebook we will simply exclude `Age`.  \n",
    "\n",
    "#### EMBARKED\n",
    "\n",
    "The test data does not have any missing values for `Embarked`. As only around `0.2%` of these values are missing in the training dataset, entries with missing `Embarked` value can be excluded in training.\n",
    "\n",
    "#### CABIN\n",
    "\n",
    "Over both the training and test data, see that almost `80%` of`Cabin` data is not recorded. It would be difficult to fill in this much of data given only `20%` and so this field is likely to have little influence on the final prediction. We will exclude the `Cabin` datafield.\n",
    "\n",
    "#### FARE\n",
    "\n",
    "There are no empty values for `Fare` in the training data and only `0.24%` of these values are missing in the test data. If we were to exclude this field from the test data, we would have to exclude it from the training data. We are better off simply filling it in the test data. We can do this by replacing all `null` values with the `Fare` datafield average. \n",
    "\n",
    "**Remark.** *For a slightly more accurate fill, we could use that `Fare` is probably dependent on passenger class. Since the passenger class, `Pclass` is known, we can fill in the `Fare` datafield by the average of this datafield for the given `Pclass`. E.g., if `Pclass` for the missing fare is `1`, we can look at the average fare for first class passengers and use this value for the missing fare.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535d7745-23bb-4136-9bff-99814825160e",
   "metadata": {},
   "source": [
    "### DATA PREPARATION\n",
    "\n",
    "#### REMOVAL\n",
    "\n",
    "Based on the preliminary conclusion reached above, we will remove unecessary columns and ensure that any categorical data is of numerical type. The columns with their data types are: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2525e95-8140-4093-b694-85182c655a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId: has data type int64\n",
      "Survived: has data type int64\n",
      "Pclass: has data type int64\n",
      "Name: has data type object\n",
      "Sex: has data type object\n",
      "Age: has data type float64\n",
      "SibSp: has data type int64\n",
      "Parch: has data type int64\n",
      "Ticket: has data type object\n",
      "Fare: has data type float64\n",
      "Cabin: has data type object\n",
      "Embarked: has data type object\n"
     ]
    }
   ],
   "source": [
    "for col in list(trainData.columns):\n",
    "    print(f\"{col}: has data type {trainData[col].dtypes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c332ac-727e-4710-bc3c-1a3129bd4b10",
   "metadata": {},
   "source": [
    "Columns which we expect would *not* be useful in predicting survival are `PassengerId`, `Name` and `Ticket`. \n",
    "\n",
    "**Remark.** *One could imagine `Name` to be useful however if it contained prefixes such as `Dr.`, `Mr.`, `Mrs.` as people with such titles might influence their chance of survival. In preparing the data in this notebook however we do not assume this and consider `Name` irrelevant.*\n",
    "\n",
    "We can remove these columns from both datasets. We will retain `PassengerId` in the test data however since, in the final submission of predictions, we are required to submit passenger survivor predictions along with their ID. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e544cb72-2345-4038-b347-5c4e7eecbecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = trainData.drop([\"PassengerId\", \"Name\", \"Ticket\", \"Age\", \"Cabin\"], axis=1)\n",
    "testData = testData.drop([\"Name\", \"Ticket\", \"Age\", \"Cabin\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96459f82-f0e3-4784-b6ef-0bcbc7227be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survived', 'Pclass', 'Sex', 'SibSp', 'Parch', 'Fare', 'Embarked'], dtype='object')\n",
      "Index(['PassengerId', 'Pclass', 'Sex', 'SibSp', 'Parch', 'Fare', 'Embarked'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(trainData.columns)\n",
    "print(testData.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a288052-aa4f-411f-b755-171f6ab8bf8d",
   "metadata": {},
   "source": [
    "Reindexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2454473f-917a-4b8e-89b8-b5822ff791bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = trainData.reset_index(drop=True)\n",
    "testData = testData.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dff2e6-e093-4923-80b8-d7c2908bed81",
   "metadata": {},
   "source": [
    "### DATA NUMERICIZATION\n",
    "\n",
    "The training and test data contain both numerical and categorical data. The categorical data can be mapped to numbers through the method of `one-hot encoding`, e.g., `Sex` can be encoded by `0` or `1` according to categorical values `male` and `female` and similarly for `Embarked`.\n",
    "\n",
    "In the approach of `one-hot encoding`, each category appears as a separate column in the dataset. The value of `1` or `0` is recorded according to whether this property is true or false in the entry respectively.\n",
    "\n",
    "Doing this for the training and test data below gives a new, one-hot encoded numericized dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c68c021-4c18-4b42-a649-16706daf619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainNumerCols = [\n",
    "            'Survived',\n",
    "            'Pclass',\n",
    "            \"male\",\n",
    "            \"female\",\n",
    "            'SibSp',\n",
    "            'Parch',\n",
    "            'Fare',\n",
    "            \"embarkedC\",\n",
    "            \"embarkedS\",\n",
    "            \"embarkedQ\"\n",
    "        ]\n",
    "\n",
    "list(trainData.columns)\n",
    "trainNumer = pd.DataFrame(columns = trainNumerCols)\n",
    "\n",
    "for i, row in trainData.iterrows():\n",
    "    \n",
    "    male = 0\n",
    "    if row[\"Sex\"] == 'male':\n",
    "        male = 1\n",
    "    \n",
    "    female = 0\n",
    "    if row['Sex'] == 'female':\n",
    "        female = 1\n",
    "        \n",
    "    embC = 0\n",
    "    if row['Embarked'] == 'C':\n",
    "        embC = 1\n",
    "        \n",
    "    embS = 0\n",
    "    if row['Embarked'] == 'S':\n",
    "        embS = 1\n",
    "    \n",
    "    embQ = 0\n",
    "    if row['Embarked'] == 'Q':\n",
    "        embQ = 1\n",
    "\n",
    "    trainNumer = trainNumer.append(pd.Series(\n",
    "        [\n",
    "            row['Survived'],\n",
    "            row['Pclass'],\n",
    "            male,\n",
    "            female,\n",
    "            row['SibSp'],\n",
    "            row['Parch'],\n",
    "            row['Fare'],\n",
    "            embC,\n",
    "            embS,\n",
    "            embQ\n",
    "        ], index = trainNumerCols\n",
    "    ), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1da26a3e-348f-4d73-b164-a6743db67402",
   "metadata": {},
   "outputs": [],
   "source": [
    "testNumerCols = [\n",
    "    'PassengerId',\n",
    "    'Pclass',\n",
    "    'male',\n",
    "    'female',\n",
    "    'SibSp',\n",
    "    'Parch',\n",
    "    'Fare',\n",
    "    'embarkedC',\n",
    "    'embarkedS',\n",
    "    'embarkedQ'\n",
    "]\n",
    "testNumer = pd.DataFrame(columns=testNumerCols)\n",
    "\n",
    "for i, row in testData.iterrows():\n",
    "\n",
    "    male = 0\n",
    "    if row[\"Sex\"] == 'male':\n",
    "        male = 1\n",
    "    \n",
    "    female = 0\n",
    "    if row['Sex'] == 'female':\n",
    "        female = 1\n",
    "        \n",
    "    embC = 0\n",
    "    if row['Embarked'] == 'C':\n",
    "        embC = 1\n",
    "        \n",
    "    embS = 0\n",
    "    if row['Embarked'] == 'S':\n",
    "        embS = 1\n",
    "    \n",
    "    embQ = 0\n",
    "    if row['Embarked'] == 'Q':\n",
    "        embQ = 1\n",
    "        \n",
    "    if pd.isnull(testData[\"Fare\"][i]):\n",
    "        fare = testData[\"Fare\"].mean()\n",
    "    else:\n",
    "        fare = row[\"Fare\"]\n",
    "    \n",
    "    testNumer = testNumer.append(pd.Series(\n",
    "        [\n",
    "            row['PassengerId'],\n",
    "            row['Pclass'],\n",
    "            male,\n",
    "            female,\n",
    "            row['SibSp'],\n",
    "            row['Parch'],\n",
    "            fare,\n",
    "            embC,\n",
    "            embS,\n",
    "            embQ\n",
    "        ], index = testNumerCols\n",
    "    ), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa96a3d-d56a-42ac-aebb-27005babb7ab",
   "metadata": {},
   "source": [
    "### OUTPUT\n",
    "\n",
    "\n",
    "Now that the datasets have been analysed and numericized, we can output them to `.csv` files, ready to be parsed by a machine learning model. For supervised machine learning models we need to parse *training data*, *training data labels* and the *test data*. Validation, if specified, is implemented on training data.\n",
    "\n",
    "#### TRAINING DATA OUTPUTS\n",
    "\n",
    "Note, labels for training data is the column `Survived`. Accordingly, this is removed in forming the training data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c9bca05-0755-43cf-8e37-9b5e8ae03e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = trainNumer.drop(['Survived'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4c8f47-bbe6-4f27-a47f-ffed2a81963d",
   "metadata": {},
   "source": [
    "Labels for the training data is the `Survived` column which we grab and output as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0806e266-954c-4539-948a-68ed0f62a2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = trainNumer[\"Survived\"].to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade8c851-2202-482e-b27b-c490270e5e90",
   "metadata": {},
   "source": [
    "There is nothing further to process concerning the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c285c89-bb7d-4e09-baee-1f7f925e1831",
   "metadata": {},
   "source": [
    "#### TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cb6064c-4a19-4c2d-8378-bd9ce2b032ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData.to_csv('datasets/trainingData.csv', index=False)\n",
    "labels.to_csv('datasets/trainingLabels.csv', index=False)\n",
    "testNumer.to_csv('datasets/testData.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
